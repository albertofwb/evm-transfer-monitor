import asyncio
import signal
import time
from collections import defaultdict, deque
from web3 import AsyncWeb3
from web3.exceptions import BlockNotFound, TransactionNotFound
from web3.middleware import ExtraDataToPOAMiddleware
from log_utils import get_logger
from config import ActiveConfig
from token_parser import TokenParser  # ÂØºÂÖ•‰ª£Â∏ÅËß£ÊûêÂô®

logger = get_logger(__name__)

class OptimizedMonitor:
    def __init__(self):
        self.w3 = AsyncWeb3(AsyncWeb3.AsyncHTTPProvider(ActiveConfig["rpc_url"]))
        self.w3.middleware_onion.inject(ExtraDataToPOAMiddleware, layer=0)
        self.is_running = True
        self.required_confirmations = 3
        
        # ‰ºòÂåñÁ≠ñÁï•ÔºöÂáèÂ∞ëRPCË∞ÉÁî®
        self.pending_by_block = defaultdict(list)  # ÊåâÂå∫ÂùóÂàÜÁªÑÔºåÈÅøÂÖçÈáçÂ§çÊü•ËØ¢
        self.confirmed_blocks = set()  # Â∑≤Á°ÆËÆ§ÁöÑÂå∫ÂùóÁºìÂ≠ò
        self.last_confirmed_check = 0  # ‰∏äÊ¨°Ê£ÄÊü•Á°ÆËÆ§ÁöÑÊó∂Èó¥
        self.confirmation_check_interval = 10  # ÊØè10ÁßíÊ£ÄÊü•‰∏ÄÊ¨°Á°ÆËÆ§Áä∂ÊÄÅ
        
        # RPCÁºìÂ≠òÊú∫Âà∂
        self.cached_block_number = None
        self.cache_time = 0
        self.cache_ttl = 1.5  # ÁºìÂ≠ò1.5ÁßíÔºåÈÅøÂÖçËøá‰∫éÈ¢ëÁπÅÊü•ËØ¢
        
        # ‰∫§ÊòìÈòàÂÄºÈÖçÁΩÆ
        self.thresholds = {
            'BNB': 1.0,        # BNB Â§ßÈ¢ù‰∫§ÊòìÈòàÂÄº
            'USDT': 10000.0,   # USDT Â§ßÈ¢ù‰∫§ÊòìÈòàÂÄº
            'USDC': 10000.0,   # USDC Â§ßÈ¢ù‰∫§ÊòìÈòàÂÄº
            'BUSD': 10000.0    # BUSD Â§ßÈ¢ù‰∫§ÊòìÈòàÂÄº
        }
        
        # ÊÄßËÉΩÁªüËÆ° - Â¢ûÂä†‰ª£Â∏ÅÁªüËÆ°
        self.stats = {
            'blocks_processed': 0,
            'transactions_found': {
                'BNB': 0,
                'USDT': 0,
                'USDC': 0,
                'BUSD': 0,
                'total': 0
            },
            'rpc_calls': 0,
            'start_time': time.time(),
            'last_stats_log': time.time(),
            'rpc_calls_by_type': {
                'get_block_number': 0,
                'get_block': 0,
                'get_gas_price': 0,
                'other': 0
            },
            'cache_hits': 0,
            'cache_misses': 0,
            'token_transactions_processed': 0,  # Â§ÑÁêÜÁöÑ‰ª£Â∏Å‰∫§ÊòìÊÄªÊï∞
            'token_contracts_detected': 0       # Ê£ÄÊµãÂà∞ÁöÑ‰ª£Â∏ÅÂêàÁ∫¶Ë∞ÉÁî®Êï∞
        }
        
        # APIÈôêÂà∂ÈÖçÁΩÆ
        self.api_limits = {
            'max_rpc_per_second': 4,
            'max_rpc_per_day': 90000,
            'daily_reset_time': None
        }

    def log_rpc_call(self, call_type='other'):
        """ËÆ∞ÂΩïRPCË∞ÉÁî®Âπ∂ÊåâÁ±ªÂûãÂàÜÁ±ªÁªüËÆ°"""
        self.stats['rpc_calls'] += 1
        if call_type in self.stats['rpc_calls_by_type']:
            self.stats['rpc_calls_by_type'][call_type] += 1
        else:
            self.stats['rpc_calls_by_type']['other'] += 1
            
        current_time = time.time()
        
        # Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÈáçÁΩÆÊØèÊó•ËÆ°Êï∞
        if self.api_limits['daily_reset_time'] is None:
            self.api_limits['daily_reset_time'] = current_time
        elif current_time - self.api_limits['daily_reset_time'] >= 86400:
            self.api_limits['daily_reset_time'] = current_time
            logger.info("üîÑ ÊØèÊó•RPCËÆ°Êï∞Â∑≤ÈáçÁΩÆ")

    async def get_cached_block_number(self):
        """Ëé∑ÂèñÁºìÂ≠òÁöÑÂå∫ÂùóÂè∑ÔºåÂáèÂ∞ëÈáçÂ§çRPCË∞ÉÁî®"""
        current_time = time.time()
        
        if (self.cached_block_number is None or 
            current_time - self.cache_time > self.cache_ttl):
            self.cached_block_number = await self.w3.eth.get_block_number()
            self.cache_time = current_time
            self.log_rpc_call('get_block_number')
            self.stats['cache_misses'] += 1
        else:
            self.stats['cache_hits'] += 1
            
        return self.cached_block_number

    async def check_api_limits(self):
        """Ê£ÄÊü•APIË∞ÉÁî®ÈôêÂà∂"""
        current_time = time.time()
        runtime = current_time - self.stats['start_time']
        
        avg_rpc_per_second = self.stats['rpc_calls'] / runtime if runtime > 0 else 0
        
        if avg_rpc_per_second > self.api_limits['max_rpc_per_second'] * 0.8:
            delay = 1.0 / self.api_limits['max_rpc_per_second']
            logger.warning(f"‚ö†Ô∏è RPCË∞ÉÁî®È¢ëÁéáËøáÈ´ò ({avg_rpc_per_second:.2f}/s)ÔºåÊ∑ªÂä† {delay:.2f}s Âª∂Ëøü")
            await asyncio.sleep(delay)
        
        if self.stats['rpc_calls'] > self.api_limits['max_rpc_per_day'] * 0.9:
            logger.warning(f"‚ö†Ô∏è ‰ªäÊó•RPCË∞ÉÁî®Ê¨°Êï∞Êé•ËøëÈôêÂà∂: {self.stats['rpc_calls']}/{self.api_limits['max_rpc_per_day']}")

    async def handle_transaction(self, tx):
        """Â§ÑÁêÜÂçï‰∏™‰∫§Êòì - ÂåÖÂê´BNBÂíå‰ª£Â∏ÅËΩ¨Ë¥¶Ê£ÄÊµãÔºàÊó†È¢ùÂ§ñRPCË∞ÉÁî®Ôºâ"""
        block_number = tx.get('blockNumber')
        
        # 1. Ê£ÄÊµãÂéüÁîü BNB ËΩ¨Ë¥¶
        wei = tx['value']
        bnb_amount = self.w3.from_wei(wei, 'ether')
        
        if bnb_amount >= self.thresholds['BNB']:
            gas_cost = self.w3.from_wei(tx['gasPrice'] * tx['gas'], 'ether')
            tx_hash = self.w3.to_hex(tx['hash'])
            
            logger.info(
                f"üí∞ Â§ßÈ¢ùBNB: {tx['from']} => {tx['to']} | "
                f"{TokenParser.format_amount(bnb_amount, 'BNB')} | "
                f"Gas: {gas_cost:,.5f} BNB | "
                f"Âå∫Âùó: {block_number} | {ActiveConfig['scan_url']}/tx/{tx_hash}"
            )
            
            if block_number:
                self.pending_by_block[block_number].append({
                    'hash': tx_hash,
                    'tx': tx,
                    'value': bnb_amount,
                    'type': 'BNB',
                    'found_at': time.time()
                })
                
            self.stats['transactions_found']['BNB'] += 1
            self.stats['transactions_found']['total'] += 1
        
        # 2. Ê£ÄÊµã‰ª£Â∏ÅËΩ¨Ë¥¶ÔºàÂ¶ÇÊûú‰∫§ÊòìË∞ÉÁî®‰∫ÜÂêàÁ∫¶Ôºâ
        if tx.get('to'):
            # Ê£ÄÊü•ÊòØÂê¶‰∏∫ÊîØÊåÅÁöÑ‰ª£Â∏ÅÂêàÁ∫¶
            token_symbol = TokenParser.is_token_contract(tx['to'])
            if token_symbol:
                self.stats['token_contracts_detected'] += 1
                
                # Ëß£Êûê‰ª£Â∏ÅËΩ¨Ë¥¶
                token_info = TokenParser.parse_erc20_transfer(tx, token_symbol)
                if token_info:
                    self.stats['token_transactions_processed'] += 1
                    
                    # Ê£ÄÊü•ÊòØÂê¶‰∏∫Â§ßÈ¢ùËΩ¨Ë¥¶
                    if token_info['amount'] >= self.thresholds.get(token_symbol, float('inf')):
                        tx_hash = self.w3.to_hex(tx['hash'])
                        
                        # Ê†πÊçÆ‰ª£Â∏ÅÁ±ªÂûãÈÄâÊã©‰∏çÂêåÁöÑÂõæÊ†á
                        icons = {
                            'USDT': 'üíµ',
                            'USDC': 'üí∏', 
                            'BUSD': 'üí¥'
                        }
                        icon = icons.get(token_symbol, 'ü™ô')
                        
                        logger.info(
                            f"{icon} Â§ßÈ¢ù{token_symbol}: {token_info['from']} => {token_info['to']} | "
                            f"{TokenParser.format_amount(token_info['amount'], token_symbol)} | "
                            f"Âå∫Âùó: {block_number} | {ActiveConfig['scan_url']}/tx/{tx_hash}"
                        )
                        
                        if block_number:
                            self.pending_by_block[block_number].append({
                                'hash': tx_hash,
                                'tx': tx,
                                'value': token_info['amount'],
                                'type': token_symbol,
                                'token_info': token_info,
                                'found_at': time.time()
                            })
                        
                        self.stats['transactions_found'][token_symbol] += 1
                        self.stats['transactions_found']['total'] += 1

    async def check_block_confirmations(self):
        """ÊâπÈáèÊ£ÄÊü•Âå∫ÂùóÁ°ÆËÆ§Áä∂ÊÄÅ"""
        if not self.pending_by_block:
            return
            
        try:
            current_block = await self.get_cached_block_number()
            await self.check_api_limits()
        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂΩìÂâçÂå∫ÂùóÂ§±Ë¥•: {e}")
            return
        
        blocks_to_remove = []
        newly_confirmed = []
        
        for block_number, tx_list in self.pending_by_block.items():
            confirmations = current_block - block_number + 1
            
            if confirmations >= self.required_confirmations:
                for tx_info in tx_list:
                    newly_confirmed.append({
                        'tx_info': tx_info,
                        'confirmations': confirmations,
                        'block_number': block_number
                    })
                blocks_to_remove.append(block_number)
                
            elif confirmations <= 0:
                logger.warning(f"‚ö†Ô∏è ÂèØËÉΩÁöÑÂå∫ÂùóÈáçÁªÑÔºåÂå∫Âùó {block_number} Á°ÆËÆ§Êï∞: {confirmations}")
        
        # ËÆ∞ÂΩïÊñ∞Á°ÆËÆ§ÁöÑ‰∫§Êòì
        for item in newly_confirmed:
            tx_info = item['tx_info']
            tx = tx_info['tx']
            confirmations = item['confirmations']
            tx_type = tx_info['type']
            
            # Ê†πÊçÆ‰∫§ÊòìÁ±ªÂûãÊ†ºÂºèÂåñÁ°ÆËÆ§‰ø°ÊÅØ
            if tx_type == 'BNB':
                logger.info(
                    f"‚úÖ BNB‰∫§ÊòìÁ°ÆËÆ§: {tx['from']} => {tx['to']} | "
                    f"{TokenParser.format_amount(tx_info['value'], 'BNB')} | "
                    f"Á°ÆËÆ§Êï∞: {confirmations} | {ActiveConfig['scan_url']}/tx/{tx_info['hash']}"
                )
            else:
                # ‰ª£Â∏Å‰∫§Êòì
                token_info = tx_info.get('token_info', {})
                logger.info(
                    f"‚úÖ {tx_type}‰∫§ÊòìÁ°ÆËÆ§: {token_info.get('from', 'N/A')} => {token_info.get('to', 'N/A')} | "
                    f"{TokenParser.format_amount(tx_info['value'], tx_type)} | "
                    f"Á°ÆËÆ§Êï∞: {confirmations} | {ActiveConfig['scan_url']}/tx/{tx_info['hash']}"
                )
        
        # Ê∏ÖÁêÜÂ∑≤Á°ÆËÆ§ÁöÑÂå∫Âùó
        for block_number in blocks_to_remove:
            del self.pending_by_block[block_number]
            
        if newly_confirmed:
            logger.debug(f"Êú¨ËΩÆÁ°ÆËÆ§‰∫Ü {len(newly_confirmed)} ‰∏™‰∫§Êòì")

    async def cleanup_old_transactions(self):
        """Ê∏ÖÁêÜË∂ÖÊó∂ÁöÑ‰∫§Êòì"""
        current_time = time.time()
        blocks_to_remove = []
        timeout_count = 0
        
        for block_number, tx_list in self.pending_by_block.items():
            remaining_txs = []
            for tx_info in tx_list:
                if current_time - tx_info['found_at'] < 300:  # 5ÂàÜÈíü
                    remaining_txs.append(tx_info)
                else:
                    timeout_count += 1
                    logger.warning(f"‚è∞ {tx_info['type']}‰∫§ÊòìÁ°ÆËÆ§Ë∂ÖÊó∂: {tx_info['hash']}")
            
            if remaining_txs:
                self.pending_by_block[block_number] = remaining_txs
            else:
                blocks_to_remove.append(block_number)
        
        for block_number in blocks_to_remove:
            del self.pending_by_block[block_number]
            
        if timeout_count > 0:
            logger.info(f"Ê∏ÖÁêÜ‰∫Ü {timeout_count} ‰∏™Ë∂ÖÊó∂‰∫§Êòì")

    def log_performance_stats(self):
        """ËÆ∞ÂΩïËØ¶ÁªÜÁöÑÊÄßËÉΩÁªüËÆ°‰ø°ÊÅØ"""
        current_time = time.time()
        runtime = current_time - self.stats['start_time']
        
        avg_rpc_per_second = self.stats['rpc_calls'] / runtime if runtime > 0 else 0
        estimated_daily_calls = avg_rpc_per_second * 86400
        
        # ÁºìÂ≠òÊïàÁéá
        total_block_requests = self.stats['cache_hits'] + self.stats['cache_misses']
        cache_hit_rate = (self.stats['cache_hits'] / total_block_requests * 100) if total_block_requests > 0 else 0
        
        pending_count = sum(len(txs) for txs in self.pending_by_block.values())
        
        # ÊåâÁ±ªÂûãÁªüËÆ°ÂæÖÁ°ÆËÆ§‰∫§Êòì
        pending_by_type = defaultdict(int)
        for tx_list in self.pending_by_block.values():
            for tx_info in tx_list:
                pending_by_type[tx_info['type']] += 1
        
        logger.info(
            f"üìä ÊÄßËÉΩÁªüËÆ° | "
            f"ËøêË°å: {runtime/3600:.1f}h | "
            f"Âå∫Âùó: {self.stats['blocks_processed']} | "
            f"‰∫§Êòì: {self.stats['transactions_found']['total']} | "
            f"ÂæÖÁ°ÆËÆ§: {pending_count}"
        )
        
        # ËØ¶ÁªÜÁöÑ‰∫§ÊòìÁ±ªÂûãÁªüËÆ°
        tx_breakdown = []
        for tx_type, count in self.stats['transactions_found'].items():
            if tx_type != 'total' and count > 0:
                pending = pending_by_type.get(tx_type, 0)
                tx_breakdown.append(f"{tx_type}: {count}({pending})")
        
        if tx_breakdown:
            logger.info(f"üí∞ ‰∫§ÊòìÂàÜÁ±ª | {' | '.join(tx_breakdown)} | (ÂèëÁé∞Êï∞(ÂæÖÁ°ÆËÆ§Êï∞))")
        
        # ‰ª£Â∏ÅÂ§ÑÁêÜÁªüËÆ°
        if self.stats['token_contracts_detected'] > 0:
            token_success_rate = (self.stats['token_transactions_processed'] / self.stats['token_contracts_detected']) * 100
            logger.info(
                f"ü™ô ‰ª£Â∏ÅÁªüËÆ° | "
                f"ÂêàÁ∫¶Ë∞ÉÁî®: {self.stats['token_contracts_detected']} | "
                f"ÊàêÂäüËß£Êûê: {self.stats['token_transactions_processed']} | "
                f"Ëß£ÊûêÁéá: {token_success_rate:.1f}%"
            )
        
        # RPCË∞ÉÁî®ÁªüËÆ°
        rpc_breakdown = " | ".join([
            f"{k}: {v}" for k, v in self.stats['rpc_calls_by_type'].items() if v > 0
        ])
        
        logger.info(
            f"üîó RPCÁªüËÆ° | "
            f"ÊÄªËÆ°: {self.stats['rpc_calls']} | "
            f"ÈÄüÁéá: {avg_rpc_per_second:.2f}/s | "
            f"È¢Ñ‰º∞Êó•Áî®: {estimated_daily_calls:.0f} | "
            f"ÁºìÂ≠òÂëΩ‰∏≠Áéá: {cache_hit_rate:.1f}%"
        )
        
        logger.info(f"üìà RPCÂàÜÁ±ª | {rpc_breakdown}")
        
        # APIÈôêÂà∂Áä∂ÊÄÅ
        if estimated_daily_calls > self.api_limits['max_rpc_per_day']:
            logger.warning(f"‚ö†Ô∏è È¢Ñ‰º∞Êó•Áî®ÈáèË∂ÖÈôêÔºÅÂΩìÂâçÈÄüÂ∫¶ÂèØËÉΩËÄóÂ∞ΩÈÖçÈ¢ù")
        elif avg_rpc_per_second > self.api_limits['max_rpc_per_second']:
            logger.warning(f"‚ö†Ô∏è RPCË∞ÉÁî®È¢ëÁéáË∂ÖÈôêÔºÅÂª∫ËÆÆÈôç‰ΩéÂà∞ {self.api_limits['max_rpc_per_second']}/s ‰ª•‰∏ã")
        else:
            logger.info(f"‚úÖ RPC‰ΩøÁî®ÁéáÊ≠£Â∏∏ÔºåÁºìÂ≠òÊúâÊïàÈôç‰Ωé‰∫ÜË∞ÉÁî®È¢ëÁéá")

    async def monitor_transactions(self):
        last_block = await self.get_cached_block_number()
        logger.info(f"üöÄ ÂºÄÂßãÁõëÊéß BNB Èìæ‰∫§ÊòìÔºàÂåÖÂê´‰ª£Â∏ÅËΩ¨Ë¥¶ÔºâÔºåÂΩìÂâçÂå∫Âùó: {last_block}")
        logger.info(f"üìà ÁõëÊéßÈòàÂÄº: BNB‚â•{self.thresholds['BNB']}, USDT‚â•{self.thresholds['USDT']:,}, USDC‚â•{self.thresholds['USDC']:,}, BUSD‚â•{self.thresholds['BUSD']:,}")
        
        while self.is_running:
            loop_start = time.time()
            
            try:
                current_block = await self.get_cached_block_number()
                await self.check_api_limits()
                
                new_blocks_processed = 0
                for block_number in range(last_block + 1, current_block + 1):
                    if not self.is_running:
                        break
                        
                    try:
                        block = await self.w3.eth.get_block(block_number, full_transactions=True)
                        self.log_rpc_call('get_block')
                        await self.check_api_limits()
                        
                        for tx in block.transactions:
                            if not self.is_running:
                                break
                            await self.handle_transaction(tx)
                        
                        new_blocks_processed += 1
                        self.stats['blocks_processed'] += 1
                        
                    except BlockNotFound:
                        continue
                    except Exception as e:
                        logger.error(f"Â§ÑÁêÜÂå∫Âùó {block_number} Â§±Ë¥•: {e}")
                        continue
                
                current_time = time.time()
                if current_time - self.last_confirmed_check >= self.confirmation_check_interval:
                    await self.check_block_confirmations()
                    self.last_confirmed_check = current_time
                
                if current_time % 60 < 1:
                    await self.cleanup_old_transactions()
                
                if current_time - self.stats['last_stats_log'] >= 300:
                    self.log_performance_stats()
                    self.stats['last_stats_log'] = current_time
                
                if current_block > last_block:
                    if new_blocks_processed > 0:
                        pending_count = sum(len(txs) for txs in self.pending_by_block.values())
                        runtime = current_time - self.stats['start_time']
                        avg_rpc_per_second = self.stats['rpc_calls'] / runtime if runtime > 0 else 0
                        
                        logger.info(
                            f"üìà Â§ÑÁêÜ {new_blocks_processed} Êñ∞Âå∫Âùó | "
                            f"ÂΩìÂâç: {current_block} | "
                            f"ÂæÖÁ°ÆËÆ§: {pending_count} | "
                            f"RPC: {self.stats['rpc_calls']} ({avg_rpc_per_second:.2f}/s) | "
                            f"ÁºìÂ≠ò: {self.stats['cache_hits']}/{self.stats['cache_hits'] + self.stats['cache_misses']} | "
                            f"ÂèëÁé∞: {self.stats['transactions_found']['total']}"
                        )
                    
                    last_block = current_block
                
                # Âä®ÊÄÅË∞ÉÊï¥Á≠âÂæÖÊó∂Èó¥
                loop_time = time.time() - loop_start
                if loop_time > 2:
                    logger.warning(f"‚ö†Ô∏è Â§ÑÁêÜËÄóÊó∂ {loop_time:.2f}sÔºåÂèØËÉΩË∑ü‰∏ç‰∏äÂá∫ÂùóÈÄüÂ∫¶")
                    await asyncio.sleep(0.1)
                else:
                    await asyncio.sleep(max(0.1, 1 - loop_time))
                
            except Exception as e:
                logger.error(f"ÁõëÊéßÂæ™ÁéØÂèëÁîüÈîôËØØ: {e}", exc_info=True)
                await asyncio.sleep(5)

        logger.info("ÁõëÊéßÂ∑≤ÂÅúÊ≠¢")

    def stop(self):
        self.is_running = False
        logger.info("Ê≠£Âú®ÂÅúÊ≠¢ÁõëÊéß...")

    def get_stats(self):
        """Ëé∑ÂèñËØ¶ÁªÜÁöÑÊÄßËÉΩÁªüËÆ°"""
        runtime = time.time() - self.stats['start_time']
        avg_rpc_per_second = self.stats['rpc_calls'] / runtime if runtime > 0 else 0
        
        # ËÆ°ÁÆóÁºìÂ≠òÊïàÁéá
        total_requests = self.stats['cache_hits'] + self.stats['cache_misses']
        cache_hit_rate = (self.stats['cache_hits'] / total_requests) if total_requests > 0 else 0
        
        return {
            'runtime_seconds': runtime,
            'runtime_hours': runtime / 3600,
            'blocks_processed': self.stats['blocks_processed'],
            'transactions_found': self.stats['transactions_found'].copy(),
            'rpc_calls_total': self.stats['rpc_calls'],
            'rpc_calls_per_second': avg_rpc_per_second,
            'rpc_calls_per_minute': avg_rpc_per_second * 60,
            'estimated_daily_rpc_calls': avg_rpc_per_second * 86400,
            'rpc_calls_by_type': self.stats['rpc_calls_by_type'].copy(),
            'cache_hit_rate': cache_hit_rate * 100,
            'cache_hits': self.stats['cache_hits'],
            'cache_misses': self.stats['cache_misses'],
            'pending_transactions': sum(len(txs) for txs in self.pending_by_block.values()),
            'api_limit_usage_percent': (self.stats['rpc_calls'] / self.api_limits['max_rpc_per_day']) * 100,
            'within_rate_limit': avg_rpc_per_second <= self.api_limits['max_rpc_per_second'],
            'token_stats': {
                'contracts_detected': self.stats['token_contracts_detected'],
                'transactions_processed': self.stats['token_transactions_processed'],
                'success_rate': (self.stats['token_transactions_processed'] / self.stats['token_contracts_detected'] * 100) if self.stats['token_contracts_detected'] > 0 else 0
            }
        }

    def update_thresholds(self, **thresholds):
        """Âä®ÊÄÅÊõ¥Êñ∞‰∫§ÊòìÈòàÂÄº"""
        for token, threshold in thresholds.items():
            if token in self.thresholds:
                old_threshold = self.thresholds[token]
                self.thresholds[token] = threshold
                logger.info(f"üîß Êõ¥Êñ∞{token}ÈòàÂÄº: {old_threshold} => {threshold}")
            else:
                logger.warning(f"‚ö†Ô∏è Êú™Áü•ÁöÑ‰ª£Â∏ÅÁ±ªÂûã: {token}")
        
        logger.info(f"üìà ÂΩìÂâçÈòàÂÄº: {self.thresholds}")


async def main():
    monitor = OptimizedMonitor()

    def signal_handler(_, _2):
        logger.info("Êé•Êî∂Âà∞ÂÅúÊ≠¢‰ø°Âè∑ÔºåÊ≠£Âú®‰ºòÈõÖÈÄÄÂá∫...")
        stats = monitor.get_stats()
        
        logger.info("=" * 80)
        logger.info("üìà ÊúÄÁªàËøêË°åÁªüËÆ°Êä•Âëä")
        logger.info(f"üïí ËøêË°åÊó∂Èïø: {stats['runtime_hours']:.2f} Â∞èÊó∂")
        logger.info(f"üì¶ Â§ÑÁêÜÂå∫Âùó: {stats['blocks_processed']} ‰∏™")
        
        # ËØ¶ÁªÜÁöÑ‰∫§ÊòìÁªüËÆ°
        tx_found = stats['transactions_found']
        logger.info(f"üí∞ ÂèëÁé∞‰∫§Êòì: {tx_found['total']} Á¨î")
        for tx_type, count in tx_found.items():
            if tx_type != 'total' and count > 0:
                logger.info(f"   {tx_type}: {count} Á¨î")
        
        # ‰ª£Â∏ÅÂ§ÑÁêÜÁªüËÆ°
        token_stats = stats['token_stats']
        if token_stats['contracts_detected'] > 0:
            logger.info(f"ü™ô ‰ª£Â∏ÅÁªüËÆ°:")
            logger.info(f"   ÂêàÁ∫¶Ë∞ÉÁî®Ê£ÄÊµã: {token_stats['contracts_detected']} Ê¨°")
            logger.info(f"   ÊàêÂäüËß£ÊûêËΩ¨Ë¥¶: {token_stats['transactions_processed']} Ê¨°")
            logger.info(f"   Ëß£ÊûêÊàêÂäüÁéá: {token_stats['success_rate']:.1f}%")
        
        # RPC‰ΩøÁî®ÁªüËÆ°
        logger.info(f"üîó RPCË∞ÉÁî®: {stats['rpc_calls_total']} Ê¨°")
        logger.info(f"‚ö° Âπ≥ÂùáÈÄüÂ∫¶: {stats['rpc_calls_per_second']:.2f} Ê¨°/Áßí")
        logger.info(f"üìä È¢Ñ‰º∞Êó•Áî®Èáè: {stats['estimated_daily_rpc_calls']:.0f} Ê¨°")
        logger.info(f"üìà ÈÖçÈ¢ù‰ΩøÁî®Áéá: {stats['api_limit_usage_percent']:.1f}%")
        logger.info(f"üéØ ÁºìÂ≠òÂëΩ‰∏≠Áéá: {stats['cache_hit_rate']:.1f}% ({stats['cache_hits']}/{stats['cache_hits']+stats['cache_misses']})")
        
        logger.info("üîç RPCË∞ÉÁî®ÂàÜÁ±ª:")
        for call_type, count in stats['rpc_calls_by_type'].items():
            if count > 0:
                percentage = (count / stats['rpc_calls_total']) * 100
                logger.info(f"   {call_type}: {count} Ê¨° ({percentage:.1f}%)")
        
        logger.info(f"‚úÖ ÈÄüÁéáÂêàËßÑ: {'ÊòØ' if stats['within_rate_limit'] else 'Âê¶'}")
        logger.info(f"‚è≥ ÂæÖÁ°ÆËÆ§‰∫§Êòì: {stats['pending_transactions']} Á¨î")
        logger.info("=" * 80)
        
        monitor.stop()

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # Ê£ÄÊü•ÁΩëÁªúËøûÊé•
    try:
        latest_block = await monitor.get_cached_block_number()
        gas_price = await monitor.w3.eth.gas_price
        monitor.log_rpc_call('get_gas_price')
        gas_price_gwei = monitor.w3.from_wei(gas_price, 'gwei')
        logger.info(f"üåê BNB ÈìæËøûÊé•ÊàêÂäü - Âå∫Âùó: {latest_block}, Gas: {gas_price_gwei:.2f} Gwei")
        
        # ÊòæÁ§∫ÊîØÊåÅÁöÑ‰ª£Â∏Å‰ø°ÊÅØ
        logger.info("ü™ô ÊîØÊåÅÁöÑ‰ª£Â∏ÅÂêàÁ∫¶:")
        for token, contract in TokenParser.CONTRACTS.items():
            if contract:
                logger.info(f"   {token}: {contract}")
        
    except Exception as e:
        logger.error(f"ÁΩëÁªúËøûÊé•Â§±Ë¥•: {e}")
        return

    # ÂºÄÂßãÁõëÊéß
    await monitor.monitor_transactions()


if __name__ == '__main__':
    asyncio.run(main())