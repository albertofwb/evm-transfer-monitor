import asyncio
import signal
import time
from collections import defaultdict, deque
from web3 import AsyncWeb3
from web3.exceptions import BlockNotFound, TransactionNotFound
from web3.middleware import ExtraDataToPOAMiddleware
from log_utils import get_logger
from config import ActiveConfig
from token_parser import TokenParser  # å¯¼å…¥ä»£å¸è§£æå™¨

logger = get_logger(__name__)

class OptimizedMonitor:
    def __init__(self):
        self.w3 = AsyncWeb3(AsyncWeb3.AsyncHTTPProvider(ActiveConfig["rpc_url"]))
        self.w3.middleware_onion.inject(ExtraDataToPOAMiddleware, layer=0)
        self.is_running = True
        self.required_confirmations = 3
        
        # ä¼˜åŒ–ç­–ç•¥ï¼šå‡å°‘RPCè°ƒç”¨
        self.pending_by_block = defaultdict(list)  # æŒ‰åŒºå—åˆ†ç»„ï¼Œé¿å…é‡å¤æŸ¥è¯¢
        self.confirmed_blocks = set()  # å·²ç¡®è®¤çš„åŒºå—ç¼“å­˜
        self.last_confirmed_check = 0  # ä¸Šæ¬¡æ£€æŸ¥ç¡®è®¤çš„æ—¶é—´
        self.confirmation_check_interval = 10  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡ç¡®è®¤çŠ¶æ€
        
        # RPCç¼“å­˜æœºåˆ¶
        self.cached_block_number = None
        self.cache_time = 0
        self.cache_ttl = 1.5  # ç¼“å­˜1.5ç§’ï¼Œé¿å…è¿‡äºé¢‘ç¹æŸ¥è¯¢
        
        # äº¤æ˜“é˜ˆå€¼é…ç½®
        self.thresholds = {
            'BNB': 1.0,        # BNB å¤§é¢äº¤æ˜“é˜ˆå€¼
            'USDT': 10000.0,   # USDT å¤§é¢äº¤æ˜“é˜ˆå€¼
            'USDC': 10000.0,   # USDC å¤§é¢äº¤æ˜“é˜ˆå€¼
            'BUSD': 10000.0    # BUSD å¤§é¢äº¤æ˜“é˜ˆå€¼
        }
        
        # æ€§èƒ½ç»Ÿè®¡ - å¢åŠ ä»£å¸ç»Ÿè®¡
        self.stats = {
            'blocks_processed': 0,
            'transactions_found': {
                'BNB': 0,
                'USDT': 0,
                'USDC': 0,
                'BUSD': 0,
                'total': 0
            },
            'rpc_calls': 0,
            'start_time': time.time(),
            'last_stats_log': time.time(),
            'rpc_calls_by_type': {
                'get_block_number': 0,
                'get_block': 0,
                'get_gas_price': 0,
                'other': 0
            },
            'cache_hits': 0,
            'cache_misses': 0,
            'token_transactions_processed': 0,  # å¤„ç†çš„ä»£å¸äº¤æ˜“æ€»æ•°
            'token_contracts_detected': 0       # æ£€æµ‹åˆ°çš„ä»£å¸åˆçº¦è°ƒç”¨æ•°
        }
        
        # APIé™åˆ¶é…ç½®
        self.api_limits = {
            'max_rpc_per_second': 4,
            'max_rpc_per_day': 90000,
            'daily_reset_time': None
        }

    def log_rpc_call(self, call_type='other'):
        """è®°å½•RPCè°ƒç”¨å¹¶æŒ‰ç±»å‹åˆ†ç±»ç»Ÿè®¡"""
        self.stats['rpc_calls'] += 1
        if call_type in self.stats['rpc_calls_by_type']:
            self.stats['rpc_calls_by_type'][call_type] += 1
        else:
            self.stats['rpc_calls_by_type']['other'] += 1
            
        current_time = time.time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®æ¯æ—¥è®¡æ•°
        if self.api_limits['daily_reset_time'] is None:
            self.api_limits['daily_reset_time'] = current_time
        elif current_time - self.api_limits['daily_reset_time'] >= 86400:
            self.api_limits['daily_reset_time'] = current_time
            logger.info("ğŸ”„ æ¯æ—¥RPCè®¡æ•°å·²é‡ç½®")

    async def get_cached_block_number(self):
        """è·å–ç¼“å­˜çš„åŒºå—å·ï¼Œå‡å°‘é‡å¤RPCè°ƒç”¨"""
        current_time = time.time()
        
        if (self.cached_block_number is None or 
            current_time - self.cache_time > self.cache_ttl):
            self.cached_block_number = await self.w3.eth.get_block_number()
            self.cache_time = current_time
            self.log_rpc_call('get_block_number')
            self.stats['cache_misses'] += 1
        else:
            self.stats['cache_hits'] += 1
            
        return self.cached_block_number

    async def check_api_limits(self):
        """æ£€æŸ¥APIè°ƒç”¨é™åˆ¶"""
        current_time = time.time()
        runtime = current_time - self.stats['start_time']
        
        avg_rpc_per_second = self.stats['rpc_calls'] / runtime if runtime > 0 else 0
        
        if avg_rpc_per_second > self.api_limits['max_rpc_per_second'] * 0.8:
            delay = 1.0 / self.api_limits['max_rpc_per_second']
            logger.warning(f"âš ï¸ RPCè°ƒç”¨é¢‘ç‡è¿‡é«˜ ({avg_rpc_per_second:.2f}/s)ï¼Œæ·»åŠ  {delay:.2f}s å»¶è¿Ÿ")
            await asyncio.sleep(delay)
        
        if self.stats['rpc_calls'] > self.api_limits['max_rpc_per_day'] * 0.9:
            logger.warning(f"âš ï¸ ä»Šæ—¥RPCè°ƒç”¨æ¬¡æ•°æ¥è¿‘é™åˆ¶: {self.stats['rpc_calls']}/{self.api_limits['max_rpc_per_day']}")

    async def handle_transaction(self, tx):
        """å¤„ç†å•ä¸ªäº¤æ˜“ - åŒ…å«BNBå’Œä»£å¸è½¬è´¦æ£€æµ‹ï¼ˆæ— é¢å¤–RPCè°ƒç”¨ï¼‰"""
        block_number = tx.get('blockNumber')
        
        # 1. æ£€æµ‹åŸç”Ÿ BNB è½¬è´¦
        wei = tx['value']
        bnb_amount = self.w3.from_wei(wei, 'ether')
        
        if bnb_amount >= self.thresholds['BNB']:
            gas_cost = self.w3.from_wei(tx['gasPrice'] * tx['gas'], 'ether')
            tx_hash = self.w3.to_hex(tx['hash'])
            
            logger.info(
                f"ğŸ’° å¤§é¢BNB: {tx['from']} => {tx['to']} | "
                f"{TokenParser.format_amount(bnb_amount, 'BNB')} | "
                f"Gas: {gas_cost:,.5f} BNB | "
                f"åŒºå—: {block_number} | {ActiveConfig['scan_url']}/tx/{tx_hash}"
            )
            
            if block_number:
                self.pending_by_block[block_number].append({
                    'hash': tx_hash,
                    'tx': tx,
                    'value': bnb_amount,
                    'type': 'BNB',
                    'found_at': time.time()
                })
                
            self.stats['transactions_found']['BNB'] += 1
            self.stats['transactions_found']['total'] += 1
        
        # 2. æ£€æµ‹ä»£å¸è½¬è´¦ï¼ˆå¦‚æœäº¤æ˜“è°ƒç”¨äº†åˆçº¦ï¼‰
        if tx.get('to'):
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„ä»£å¸åˆçº¦
            token_symbol = TokenParser.is_token_contract(tx['to'])
            if token_symbol:
                self.stats['token_contracts_detected'] += 1
                
                # è§£æä»£å¸è½¬è´¦
                token_info = TokenParser.parse_erc20_transfer(tx, token_symbol)
                if token_info:
                    self.stats['token_transactions_processed'] += 1
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºå¤§é¢è½¬è´¦
                    if token_info['amount'] >= self.thresholds.get(token_symbol, float('inf')):
                        tx_hash = self.w3.to_hex(tx['hash'])
                        
                        # æ ¹æ®ä»£å¸ç±»å‹é€‰æ‹©ä¸åŒçš„å›¾æ ‡
                        icons = {
                            'USDT': 'ğŸ’µ',
                            'USDC': 'ğŸ’¸', 
                            'BUSD': 'ğŸ’´'
                        }
                        icon = icons.get(token_symbol, 'ğŸª™')
                        
                        logger.info(
                            f"{icon} å¤§é¢{token_symbol}: {token_info['from']} => {token_info['to']} | "
                            f"{TokenParser.format_amount(token_info['amount'], token_symbol)} | "
                            f"åŒºå—: {block_number} | {ActiveConfig['scan_url']}/tx/{tx_hash}"
                        )
                        
                        if block_number:
                            self.pending_by_block[block_number].append({
                                'hash': tx_hash,
                                'tx': tx,
                                'value': token_info['amount'],
                                'type': token_symbol,
                                'token_info': token_info,
                                'found_at': time.time()
                            })
                        
                        self.stats['transactions_found'][token_symbol] += 1
                        self.stats['transactions_found']['total'] += 1

    async def check_block_confirmations(self):
        """æ‰¹é‡æ£€æŸ¥åŒºå—ç¡®è®¤çŠ¶æ€"""
        if not self.pending_by_block:
            return
            
        try:
            current_block = await self.get_cached_block_number()
            await self.check_api_limits()
        except Exception as e:
            logger.error(f"è·å–å½“å‰åŒºå—å¤±è´¥: {e}")
            return
        
        blocks_to_remove = []
        newly_confirmed = []
        
        for block_number, tx_list in self.pending_by_block.items():
            confirmations = current_block - block_number + 1
            
            if confirmations >= self.required_confirmations:
                for tx_info in tx_list:
                    newly_confirmed.append({
                        'tx_info': tx_info,
                        'confirmations': confirmations,
                        'block_number': block_number
                    })
                blocks_to_remove.append(block_number)
                
            elif confirmations <= 0:
                logger.warning(f"âš ï¸ å¯èƒ½çš„åŒºå—é‡ç»„ï¼ŒåŒºå— {block_number} ç¡®è®¤æ•°: {confirmations}")
        
        # è®°å½•æ–°ç¡®è®¤çš„äº¤æ˜“
        for item in newly_confirmed:
            tx_info = item['tx_info']
            tx = tx_info['tx']
            confirmations = item['confirmations']
            tx_type = tx_info['type']
            
            # æ ¹æ®äº¤æ˜“ç±»å‹æ ¼å¼åŒ–ç¡®è®¤ä¿¡æ¯
            if tx_type == 'BNB':
                logger.info(
                    f"âœ… BNBäº¤æ˜“ç¡®è®¤: {tx['from']} => {tx['to']} | "
                    f"{TokenParser.format_amount(tx_info['value'], 'BNB')} | "
                    f"ç¡®è®¤æ•°: {confirmations} | {ActiveConfig['scan_url']}/tx/{tx_info['hash']}"
                )
            else:
                # ä»£å¸äº¤æ˜“
                token_info = tx_info.get('token_info', {})
                logger.info(
                    f"âœ… {tx_type}äº¤æ˜“ç¡®è®¤: {token_info.get('from', 'N/A')} => {token_info.get('to', 'N/A')} | "
                    f"{TokenParser.format_amount(tx_info['value'], tx_type)} | "
                    f"ç¡®è®¤æ•°: {confirmations} | {ActiveConfig['scan_url']}/tx/{tx_info['hash']}"
                )
        
        # æ¸…ç†å·²ç¡®è®¤çš„åŒºå—
        for block_number in blocks_to_remove:
            del self.pending_by_block[block_number]
            
        if newly_confirmed:
            logger.debug(f"æœ¬è½®ç¡®è®¤äº† {len(newly_confirmed)} ä¸ªäº¤æ˜“")

    async def cleanup_old_transactions(self):
        """æ¸…ç†è¶…æ—¶çš„äº¤æ˜“"""
        current_time = time.time()
        blocks_to_remove = []
        timeout_count = 0
        
        for block_number, tx_list in self.pending_by_block.items():
            remaining_txs = []
            for tx_info in tx_list:
                if current_time - tx_info['found_at'] < 300:  # 5åˆ†é’Ÿ
                    remaining_txs.append(tx_info)
                else:
                    timeout_count += 1
                    logger.warning(f"â° {tx_info['type']}äº¤æ˜“ç¡®è®¤è¶…æ—¶: {tx_info['hash']}")
            
            if remaining_txs:
                self.pending_by_block[block_number] = remaining_txs
            else:
                blocks_to_remove.append(block_number)
        
        for block_number in blocks_to_remove:
            del self.pending_by_block[block_number]
            
        if timeout_count > 0:
            logger.info(f"æ¸…ç†äº† {timeout_count} ä¸ªè¶…æ—¶äº¤æ˜“")

    def log_performance_stats(self):
        """è®°å½•è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        current_time = time.time()
        runtime = current_time - self.stats['start_time']
        
        avg_rpc_per_second = self.stats['rpc_calls'] / runtime if runtime > 0 else 0
        estimated_daily_calls = avg_rpc_per_second * 86400
        
        # ç¼“å­˜æ•ˆç‡
        total_block_requests = self.stats['cache_hits'] + self.stats['cache_misses']
        cache_hit_rate = (self.stats['cache_hits'] / total_block_requests * 100) if total_block_requests > 0 else 0
        
        pending_count = sum(len(txs) for txs in self.pending_by_block.values())
        
        # æŒ‰ç±»å‹ç»Ÿè®¡å¾…ç¡®è®¤äº¤æ˜“
        pending_by_type = defaultdict(int)
        for tx_list in self.pending_by_block.values():
            for tx_info in tx_list:
                pending_by_type[tx_info['type']] += 1
        
        logger.info(
            f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡ | "
            f"è¿è¡Œ: {runtime/3600:.1f}h | "
            f"åŒºå—: {self.stats['blocks_processed']} | "
            f"äº¤æ˜“: {self.stats['transactions_found']['total']} | "
            f"å¾…ç¡®è®¤: {pending_count}"
        )
        
        # è¯¦ç»†çš„äº¤æ˜“ç±»å‹ç»Ÿè®¡
        tx_breakdown = []
        for tx_type, count in self.stats['transactions_found'].items():
            if tx_type != 'total' and count > 0:
                pending = pending_by_type.get(tx_type, 0)
                tx_breakdown.append(f"{tx_type}: {count}({pending})")
        
        if tx_breakdown:
            logger.info(f"ğŸ’° äº¤æ˜“åˆ†ç±» | {' | '.join(tx_breakdown)} | (å‘ç°æ•°(å¾…ç¡®è®¤æ•°))")
        
        # ä»£å¸å¤„ç†ç»Ÿè®¡
        if self.stats['token_contracts_detected'] > 0:
            token_success_rate = (self.stats['token_transactions_processed'] / self.stats['token_contracts_detected']) * 100
            logger.info(
                f"ğŸª™ ä»£å¸ç»Ÿè®¡ | "
                f"åˆçº¦è°ƒç”¨: {self.stats['token_contracts_detected']} | "
                f"æˆåŠŸè§£æ: {self.stats['token_transactions_processed']} | "
                f"è§£æç‡: {token_success_rate:.1f}%"
            )
        
        # RPCè°ƒç”¨ç»Ÿè®¡
        rpc_breakdown = " | ".join([
            f"{k}: {v}" for k, v in self.stats['rpc_calls_by_type'].items() if v > 0
        ])
        
        logger.info(
            f"ğŸ”— RPCç»Ÿè®¡ | "
            f"æ€»è®¡: {self.stats['rpc_calls']} | "
            f"é€Ÿç‡: {avg_rpc_per_second:.2f}/s | "
            f"é¢„ä¼°æ—¥ç”¨: {estimated_daily_calls:.0f} | "
            f"ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.1f}%"
        )
        
        logger.info(f"ğŸ“ˆ RPCåˆ†ç±» | {rpc_breakdown}")
        
        # APIé™åˆ¶çŠ¶æ€
        if estimated_daily_calls > self.api_limits['max_rpc_per_day']:
            logger.warning(f"âš ï¸ é¢„ä¼°æ—¥ç”¨é‡è¶…é™ï¼å½“å‰é€Ÿåº¦å¯èƒ½è€—å°½é…é¢")
        elif avg_rpc_per_second > self.api_limits['max_rpc_per_second']:
            logger.warning(f"âš ï¸ RPCè°ƒç”¨é¢‘ç‡è¶…é™ï¼å»ºè®®é™ä½åˆ° {self.api_limits['max_rpc_per_second']}/s ä»¥ä¸‹")
        else:
            logger.info(f"âœ… RPCä½¿ç”¨ç‡æ­£å¸¸ï¼Œç¼“å­˜æœ‰æ•ˆé™ä½äº†è°ƒç”¨é¢‘ç‡")

    async def monitor_transactions(self):
        last_block = await self.get_cached_block_number()
        logger.info(f"ğŸš€ å¼€å§‹ç›‘æ§ BNB é“¾äº¤æ˜“ï¼ˆåŒ…å«ä»£å¸è½¬è´¦ï¼‰ï¼Œå½“å‰åŒºå—: {last_block}")
        logger.info(f"ğŸ“ˆ ç›‘æ§é˜ˆå€¼: BNBâ‰¥{self.thresholds['BNB']}, USDTâ‰¥{self.thresholds['USDT']:,}, USDCâ‰¥{self.thresholds['USDC']:,}, BUSDâ‰¥{self.thresholds['BUSD']:,}")
        
        while self.is_running:
            loop_start = time.time()
            
            try:
                current_block = await self.get_cached_block_number()
                await self.check_api_limits()
                
                new_blocks_processed = 0
                for block_number in range(last_block + 1, current_block + 1):
                    if not self.is_running:
                        break
                        
                    try:
                        block = await self.w3.eth.get_block(block_number, full_transactions=True)
                        self.log_rpc_call('get_block')
                        await self.check_api_limits()
                        
                        for tx in block.transactions:
                            if not self.is_running:
                                break
                            await self.handle_transaction(tx)
                        
                        new_blocks_processed += 1
                        self.stats['blocks_processed'] += 1
                        
                    except BlockNotFound:
                        continue
                    except Exception as e:
                        logger.error(f"å¤„ç†åŒºå— {block_number} å¤±è´¥: {e}")
                        continue
                
                current_time = time.time()
                if current_time - self.last_confirmed_check >= self.confirmation_check_interval:
                    await self.check_block_confirmations()
                    self.last_confirmed_check = current_time
                
                if current_time % 60 < 1:
                    await self.cleanup_old_transactions()
                
                if current_time - self.stats['last_stats_log'] >= 300:
                    self.log_performance_stats()
                    self.stats['last_stats_log'] = current_time
                
                if current_block > last_block:
                    if new_blocks_processed > 0:
                        pending_count = sum(len(txs) for txs in self.pending_by_block.values())
                        runtime = current_time - self.stats['start_time']
                        avg_rpc_per_second = self.stats['rpc_calls'] / runtime if runtime > 0 else 0
                        
                        logger.info(
                            f"ğŸ“ˆ å¤„ç† {new_blocks_processed} æ–°åŒºå— | "
                            f"å½“å‰: {current_block} | "
                            f"å¾…ç¡®è®¤: {pending_count} | "
                            f"RPC: {self.stats['rpc_calls']} ({avg_rpc_per_second:.2f}/s) | "
                            f"ç¼“å­˜: {self.stats['cache_hits']}/{self.stats['cache_hits'] + self.stats['cache_misses']} | "
                            f"å‘ç°: {self.stats['transactions_found']['total']}"
                        )
                    
                    last_block = current_block
                
                # åŠ¨æ€è°ƒæ•´ç­‰å¾…æ—¶é—´
                loop_time = time.time() - loop_start
                if loop_time > 2:
                    logger.warning(f"âš ï¸ å¤„ç†è€—æ—¶ {loop_time:.2f}sï¼Œå¯èƒ½è·Ÿä¸ä¸Šå‡ºå—é€Ÿåº¦")
                    await asyncio.sleep(0.1)
                else:
                    await asyncio.sleep(max(0.1, 1 - loop_time))
                
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                await asyncio.sleep(5)

        logger.info("ç›‘æ§å·²åœæ­¢")

    def stop(self):
        self.is_running = False
        logger.info("æ­£åœ¨åœæ­¢ç›‘æ§...")

    def get_stats(self):
        """è·å–è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡"""
        runtime = time.time() - self.stats['start_time']
        avg_rpc_per_second = self.stats['rpc_calls'] / runtime if runtime > 0 else 0
        
        # è®¡ç®—ç¼“å­˜æ•ˆç‡
        total_requests = self.stats['cache_hits'] + self.stats['cache_misses']
        cache_hit_rate = (self.stats['cache_hits'] / total_requests) if total_requests > 0 else 0
        
        return {
            'runtime_seconds': runtime,
            'runtime_hours': runtime / 3600,
            'blocks_processed': self.stats['blocks_processed'],
            'transactions_found': self.stats['transactions_found'].copy(),
            'rpc_calls_total': self.stats['rpc_calls'],
            'rpc_calls_per_second': avg_rpc_per_second,
            'rpc_calls_per_minute': avg_rpc_per_second * 60,
            'estimated_daily_rpc_calls': avg_rpc_per_second * 86400,
            'rpc_calls_by_type': self.stats['rpc_calls_by_type'].copy(),
            'cache_hit_rate': cache_hit_rate * 100,
            'cache_hits': self.stats['cache_hits'],
            'cache_misses': self.stats['cache_misses'],
            'pending_transactions': sum(len(txs) for txs in self.pending_by_block.values()),
            'api_limit_usage_percent': (self.stats['rpc_calls'] / self.api_limits['max_rpc_per_day']) * 100,
            'within_rate_limit': avg_rpc_per_second <= self.api_limits['max_rpc_per_second'],
            'token_stats': {
                'contracts_detected': self.stats['token_contracts_detected'],
                'transactions_processed': self.stats['token_transactions_processed'],
                'success_rate': (self.stats['token_transactions_processed'] / self.stats['token_contracts_detected'] * 100) if self.stats['token_contracts_detected'] > 0 else 0
            }
        }

    def update_thresholds(self, **thresholds):
        """åŠ¨æ€æ›´æ–°äº¤æ˜“é˜ˆå€¼"""
        for token, threshold in thresholds.items():
            if token in self.thresholds:
                old_threshold = self.thresholds[token]
                self.thresholds[token] = threshold
                logger.info(f"ğŸ”§ æ›´æ–°{token}é˜ˆå€¼: {old_threshold} => {threshold}")
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥çš„ä»£å¸ç±»å‹: {token}")
        
        logger.info(f"ğŸ“ˆ å½“å‰é˜ˆå€¼: {self.thresholds}")


async def main():
    monitor = OptimizedMonitor()

    def signal_handler(_, _2):
        logger.info("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
        stats = monitor.get_stats()
        
        logger.info("=" * 80)
        logger.info("ğŸ“ˆ æœ€ç»ˆè¿è¡Œç»Ÿè®¡æŠ¥å‘Š")
        logger.info(f"ğŸ•’ è¿è¡Œæ—¶é•¿: {stats['runtime_hours']:.2f} å°æ—¶")
        logger.info(f"ğŸ“¦ å¤„ç†åŒºå—: {stats['blocks_processed']} ä¸ª")
        
        # è¯¦ç»†çš„äº¤æ˜“ç»Ÿè®¡
        tx_found = stats['transactions_found']
        logger.info(f"ğŸ’° å‘ç°äº¤æ˜“: {tx_found['total']} ç¬”")
        for tx_type, count in tx_found.items():
            if tx_type != 'total' and count > 0:
                logger.info(f"   {tx_type}: {count} ç¬”")
        
        # ä»£å¸å¤„ç†ç»Ÿè®¡
        token_stats = stats['token_stats']
        if token_stats['contracts_detected'] > 0:
            logger.info(f"ğŸª™ ä»£å¸ç»Ÿè®¡:")
            logger.info(f"   åˆçº¦è°ƒç”¨æ£€æµ‹: {token_stats['contracts_detected']} æ¬¡")
            logger.info(f"   æˆåŠŸè§£æè½¬è´¦: {token_stats['transactions_processed']} æ¬¡")
            logger.info(f"   è§£ææˆåŠŸç‡: {token_stats['success_rate']:.1f}%")
        
        # RPCä½¿ç”¨ç»Ÿè®¡
        logger.info(f"ğŸ”— RPCè°ƒç”¨: {stats['rpc_calls_total']} æ¬¡")
        logger.info(f"âš¡ å¹³å‡é€Ÿåº¦: {stats['rpc_calls_per_second']:.2f} æ¬¡/ç§’")
        logger.info(f"ğŸ“Š é¢„ä¼°æ—¥ç”¨é‡: {stats['estimated_daily_rpc_calls']:.0f} æ¬¡")
        logger.info(f"ğŸ“ˆ é…é¢ä½¿ç”¨ç‡: {stats['api_limit_usage_percent']:.1f}%")
        logger.info(f"ğŸ¯ ç¼“å­˜å‘½ä¸­ç‡: {stats['cache_hit_rate']:.1f}% ({stats['cache_hits']}/{stats['cache_hits']+stats['cache_misses']})")
        
        logger.info("ğŸ” RPCè°ƒç”¨åˆ†ç±»:")
        for call_type, count in stats['rpc_calls_by_type'].items():
            if count > 0:
                percentage = (count / stats['rpc_calls_total']) * 100
                logger.info(f"   {call_type}: {count} æ¬¡ ({percentage:.1f}%)")
        
        logger.info(f"âœ… é€Ÿç‡åˆè§„: {'æ˜¯' if stats['within_rate_limit'] else 'å¦'}")
        logger.info(f"â³ å¾…ç¡®è®¤äº¤æ˜“: {stats['pending_transactions']} ç¬”")
        logger.info("=" * 80)
        
        monitor.stop()

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # æ£€æŸ¥ç½‘ç»œè¿æ¥
    try:
        latest_block = await monitor.get_cached_block_number()
        gas_price = await monitor.w3.eth.gas_price
        monitor.log_rpc_call('get_gas_price')
        gas_price_gwei = monitor.w3.from_wei(gas_price, 'gwei')
        logger.info(f"ğŸŒ BNB é“¾è¿æ¥æˆåŠŸ - åŒºå—: {latest_block}, Gas: {gas_price_gwei:.2f} Gwei")
        
        # æ˜¾ç¤ºæ”¯æŒçš„ä»£å¸ä¿¡æ¯
        logger.info("ğŸª™ æ”¯æŒçš„ä»£å¸åˆçº¦:")
        for token, contract in TokenParser.CONTRACTS.items():
            if contract:
                logger.info(f"   {token}: {contract}")
        
    except Exception as e:
        logger.error(f"ç½‘ç»œè¿æ¥å¤±è´¥: {e}")
        return

    # å¼€å§‹ç›‘æ§
    await monitor.monitor_transactions()


if __name__ == '__main__':
    asyncio.run(main())